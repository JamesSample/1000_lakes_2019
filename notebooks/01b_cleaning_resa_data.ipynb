{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import nivapy3 as nivapy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Username:  ···\n",
      "Password:  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful.\n"
     ]
    }
   ],
   "source": [
    "eng = nivapy.da.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1000 Lakes 2019 (Part 1b: Further cleaning of RESA2)\n",
    "\n",
    "This notebook attempts to fix further data issues in RESA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Duplicated/incorrect dates\n",
    "\n",
    "The 1000 Lakes samples were split and analysed separately for metals. However, there seems to have been a mix-up, and some samples have come back with different dates. An e-mail from Liv Bente (received 05.06.2020 at 17.14) identifies which samples are duplicates and which are from other projects. The code below merges and corrects the duplicates based on Liv Bente's spreadsheet.\n",
    "\n",
    "Roar has done something similar in AM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lbs_comment</th>\n",
       "      <th>station_code</th>\n",
       "      <th>dup</th>\n",
       "      <th>station_name</th>\n",
       "      <th>sample_date</th>\n",
       "      <th>cor_sample_date</th>\n",
       "      <th>excel_date</th>\n",
       "      <th>depth1</th>\n",
       "      <th>depth2</th>\n",
       "      <th>cor_depth1</th>\n",
       "      <th>cor_depth2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dyp er feil, skal være  0 m</td>\n",
       "      <td>434-1-11</td>\n",
       "      <td>1</td>\n",
       "      <td>Abbortjørna</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tusen, dyp &amp; prøvedato ok</td>\n",
       "      <td>434-1-11</td>\n",
       "      <td>1</td>\n",
       "      <td>Abbortjørna</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tusen, prøvedato ok</td>\n",
       "      <td>1866-1-11</td>\n",
       "      <td>1</td>\n",
       "      <td>Austpollvatnan</td>\n",
       "      <td>2019-09-24</td>\n",
       "      <td>2019-09-24</td>\n",
       "      <td>2019-09-24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prøvedato 1 dag feil</td>\n",
       "      <td>1866-1-11</td>\n",
       "      <td>1</td>\n",
       "      <td>Austpollvatnan</td>\n",
       "      <td>2019-09-23</td>\n",
       "      <td>2019-09-24</td>\n",
       "      <td>2019-09-23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tusen, prøvedato ok</td>\n",
       "      <td>616-2-20</td>\n",
       "      <td>1</td>\n",
       "      <td>Belgevatnet</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   lbs_comment station_code  dup    station_name sample_date  \\\n",
       "0  Dyp er feil, skal være  0 m     434-1-11    1     Abbortjørna  2019-10-15   \n",
       "1    Tusen, dyp & prøvedato ok     434-1-11    1     Abbortjørna  2019-10-15   \n",
       "2          Tusen, prøvedato ok    1866-1-11    1  Austpollvatnan  2019-09-24   \n",
       "3         Prøvedato 1 dag feil    1866-1-11    1  Austpollvatnan  2019-09-23   \n",
       "4          Tusen, prøvedato ok     616-2-20    1     Belgevatnet  2019-10-02   \n",
       "\n",
       "  cor_sample_date excel_date  depth1  depth2  cor_depth1  cor_depth2  \n",
       "0      2019-10-15 2019-10-15       2       2         0.0         0.0  \n",
       "1      2019-10-15 2019-10-15       0       0         0.0         0.0  \n",
       "2      2019-09-24 2019-09-24       0       0         0.0         0.0  \n",
       "3      2019-09-24 2019-09-23       0       0         0.0         0.0  \n",
       "4      2019-10-02 2019-10-02       0       0         0.0         0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data from Liv Bente\n",
    "xl_path = r\"../../../quality_control/resa_date_errors_2020-06-11.xlsx\"\n",
    "df = pd.read_excel(xl_path)\n",
    "df['sample_date'] = pd.to_datetime(df['sample_date'], format='%d.%m.%Y %H.%M.%S')\n",
    "df['cor_sample_date'] = pd.to_datetime(df['cor_sample_date'], format='%d.%m.%Y %H.%M.%S')\n",
    "df['cor_depth1'].fillna(0, inplace=True)\n",
    "df['cor_depth2'].fillna(0, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_code</th>\n",
       "      <th>station_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>altitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3167</td>\n",
       "      <td>620-4-6</td>\n",
       "      <td>Ørteren</td>\n",
       "      <td>60.470</td>\n",
       "      <td>7.795</td>\n",
       "      <td>1147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3168</td>\n",
       "      <td>621-1-27</td>\n",
       "      <td>Flåvatna</td>\n",
       "      <td>60.200</td>\n",
       "      <td>9.183</td>\n",
       "      <td>855.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3169</td>\n",
       "      <td>621-3-5</td>\n",
       "      <td>Soneren</td>\n",
       "      <td>60.061</td>\n",
       "      <td>9.545</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3170</td>\n",
       "      <td>622-2-43</td>\n",
       "      <td>Trytetjern</td>\n",
       "      <td>60.213</td>\n",
       "      <td>9.764</td>\n",
       "      <td>275.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3171</td>\n",
       "      <td>622-4-4</td>\n",
       "      <td>Krøderen</td>\n",
       "      <td>60.327</td>\n",
       "      <td>9.645</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id station_code station_name  latitude  longitude  altitude\n",
       "0        3167      620-4-6      Ørteren    60.470      7.795    1147.0\n",
       "1        3168     621-1-27     Flåvatna    60.200      9.183     855.0\n",
       "2        3169      621-3-5      Soneren    60.061      9.545     104.0\n",
       "3        3170     622-2-43   Trytetjern    60.213      9.764     275.0\n",
       "4        3171      622-4-4     Krøderen    60.327      9.645     133.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get stations\n",
    "stn_df = nivapy.da.select_resa_project_stations([4530], eng)\n",
    "stn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is messy. It iterates through the stations in Liv Bente's spreadsheet and corrects/merges the issues highlighted. In most cases, this means taking two water samples and combining them. Note that I haven't favoured any particular sample ID as the \"original\" - I've just picked one of the duplicates, merged it with the other, then updated the sample properties (date and depth) so they are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loop over \"problem\" stations\n",
    "#for stn_cde in df['station_code'].unique():\n",
    "#    stn_id = stn_df.query(\"station_code == @stn_cde\")['station_id'].iloc[0]\n",
    "#    df2 = df.query(\"station_code == @stn_cde\")\n",
    "#    \n",
    "#    if len(df2) == 1:\n",
    "#        # Just one sample. Check OK\n",
    "#        assert (df2['sample_date'] == df2['cor_sample_date']).all(), df2\n",
    "#        assert (df2['depth1'] == df2['cor_depth1']).all(), df2\n",
    "#        assert (df2['depth2'] == df2['cor_depth2']).all(), df2\n",
    "#        \n",
    "#    elif len(df2) == 2:\n",
    "#        # Get correct date\n",
    "#        cor_date = df2['cor_sample_date'].unique()\n",
    "#        assert len(cor_date) == 1\n",
    "#        cor_date = np.datetime_as_string(cor_date)[0][:10]\n",
    "#        \n",
    "#        # Get duplicated water sample IDs\n",
    "#        ws_ids = []\n",
    "#        for idx, row in df2.iterrows():\n",
    "#            date = row['sample_date'].strftime('%Y-%m-%d')\n",
    "#            dep1 = row['depth1']\n",
    "#            dep2 = row['depth2']  \n",
    "#            \n",
    "#            sql = (f\"SELECT * FROM resa2.water_samples \"\n",
    "#                   f\"WHERE station_id = {stn_id} \"\n",
    "#                   f\"AND TRUNC(sample_date) = DATE '{date}' \"\n",
    "#                   f\"AND depth1 = {dep1} \"\n",
    "#                   f\"AND depth2 = {dep2} \"\n",
    "#                  )\n",
    "#            ws_df = pd.read_sql(sql, eng)\n",
    "#            assert len(ws_df) == 1, (stn_cde, ws_df)\n",
    "#            ws_id = ws_df['water_sample_id'].iloc[0]\n",
    "#            ws_ids.append(ws_id)\n",
    "#            \n",
    "#        assert len(ws_ids) == 2\n",
    "#        assert ws_ids[0] != ws_ids[1]\n",
    "#    \n",
    "#        # Move all chem values to first water sample. The choice is arbitrary\n",
    "#        cor_ws = ws_ids[0]\n",
    "#        bad_ws = ws_ids[1]        \n",
    "#        sql = (f\"UPDATE resa2.water_chemistry_values2 \"\n",
    "#               f\"SET sample_id = {cor_ws} \"\n",
    "#               f\"WHERE sample_id = {bad_ws}\")\n",
    "#        eng.execute(sql)\n",
    "#        \n",
    "#        # Delete \"bad\" ws\n",
    "#        sql = (f\"DELETE FROM resa2.labware_wsid \"\n",
    "#               f\"WHERE water_sample_id = {bad_ws}\")\n",
    "#        eng.execute(sql)\n",
    "#        \n",
    "#        sql = (f\"DELETE FROM resa2.water_samples \"\n",
    "#               f\"WHERE water_sample_id = {bad_ws}\")\n",
    "#        eng.execute(sql)\n",
    "#        \n",
    "#        # Assign correct date and depths to \"good\" ws\n",
    "#        sql = (f\"UPDATE resa2.water_samples \"\n",
    "#               f\"SET \"\n",
    "#               f\"  sample_date = TO_DATE('{cor_date}', 'yyyy-mm-dd'), \"\n",
    "#               f\"  depth1 = 0, \"\n",
    "#               f\"  depth2 = 0 \"\n",
    "#               f\"WHERE water_sample_id = {cor_ws}\"\n",
    "#              )\n",
    "#        eng.execute(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Synchronise with AM\n",
    "\n",
    "Roar has fixed the duplicated dates in AM (see e-mail received 10.06.2020 at 15.46). I have then exported the latest data from AM and removed samples collected as part of other projects (again, based on the spreadsheet from Liv Bente). This leaves a spreadsheet with a fairly complete-looing record of 1001 water samples. This seems reasonable: there are 1003 stations in the project in total, but one lake has \"disappeared\" and Store Ljøsvatnet was sampled by mistake in 2019 in place of Ljøsvannet (which was part of the 1995 survey). Both are part of the 1000 Lakes project, but the latter was not sampled in 2019. 1001 samples therefore seems correct.\n",
    "\n",
    "The code below attempts to match this spreadsheet to the data in AM, with the following aims:\n",
    "\n",
    " 1. Check that the samples in AM can be correctly identified in RESA and update sample metadata if necessary\n",
    " \n",
    " 2. Update the values in RESA to match those in AM\n",
    " \n",
    " 2. Add the relevant RESA water sample IDs to the `SAMPLE_SELECTIONS` table, so that just the 2019 1000 Lakes dataset is available from RESA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Create sample selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_selection_id</th>\n",
       "      <th>project_id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>4530</td>\n",
       "      <td>Nasjonal Innsjøundersøkelse 2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_selection_id  project_id                              name\n",
       "0                   67        4530  Nasjonal Innsjøundersøkelse 2019"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_df = pd.DataFrame({'sample_selection_id': [67],\n",
    "                      'project_id': [4530],\n",
    "                      'name': ['Nasjonal Innsjøundersøkelse 2019']})\n",
    "ss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ss_df.to_sql('sample_selection_definitions',\n",
    "#             schema='resa2',\n",
    "#             if_exists='append',\n",
    "#             index=False,\n",
    "#             con=eng,\n",
    "#            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Match water samples and populate \"sample selection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_id</th>\n",
       "      <th>project_name</th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_code</th>\n",
       "      <th>station_name</th>\n",
       "      <th>sample_date</th>\n",
       "      <th>excel_date</th>\n",
       "      <th>depth1</th>\n",
       "      <th>depth2</th>\n",
       "      <th>Al</th>\n",
       "      <th>...</th>\n",
       "      <th>PO4-P</th>\n",
       "      <th>SiO2</th>\n",
       "      <th>SO4</th>\n",
       "      <th>Temperatur</th>\n",
       "      <th>TOC</th>\n",
       "      <th>TOTN</th>\n",
       "      <th>TOTP</th>\n",
       "      <th>V</th>\n",
       "      <th>Zn</th>\n",
       "      <th>Zn.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12433</td>\n",
       "      <td>Nasjonal Innsjøundersøkelse 2019</td>\n",
       "      <td>26472</td>\n",
       "      <td>1001-1-55</td>\n",
       "      <td>Skeivatnet</td>\n",
       "      <td>30.10.2019 00.00.00</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt; 1</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1.32</td>\n",
       "      <td>8.2</td>\n",
       "      <td>9.2</td>\n",
       "      <td>390</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12433</td>\n",
       "      <td>Nasjonal Innsjøundersøkelse 2019</td>\n",
       "      <td>71862</td>\n",
       "      <td>1001-2-204</td>\n",
       "      <td>Vassvann</td>\n",
       "      <td>29.10.2019 00.00.00</td>\n",
       "      <td>2019-10-29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt; 1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.13</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.8</td>\n",
       "      <td>380</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12433</td>\n",
       "      <td>Nasjonal Innsjøundersøkelse 2019</td>\n",
       "      <td>26474</td>\n",
       "      <td>1002-1-62</td>\n",
       "      <td>Vråvatn</td>\n",
       "      <td>30.10.2019 00.00.00</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>220</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>2.24</td>\n",
       "      <td>2.19</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>520</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12433</td>\n",
       "      <td>Nasjonal Innsjøundersøkelse 2019</td>\n",
       "      <td>26475</td>\n",
       "      <td>1003-1-16</td>\n",
       "      <td>HOH 130</td>\n",
       "      <td>30.10.2019 00.00.00</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt; 1</td>\n",
       "      <td>1.87</td>\n",
       "      <td>1.69</td>\n",
       "      <td>8.1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>280</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12433</td>\n",
       "      <td>Nasjonal Innsjøundersøkelse 2019</td>\n",
       "      <td>26476</td>\n",
       "      <td>1003-1-18</td>\n",
       "      <td>HOH 14</td>\n",
       "      <td>30.10.2019 00.00.00</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt; 1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.45</td>\n",
       "      <td>8.6</td>\n",
       "      <td>3.3</td>\n",
       "      <td>270</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   project_id                      project_name  station_id station_code  \\\n",
       "0       12433  Nasjonal Innsjøundersøkelse 2019       26472    1001-1-55   \n",
       "1       12433  Nasjonal Innsjøundersøkelse 2019       71862   1001-2-204   \n",
       "2       12433  Nasjonal Innsjøundersøkelse 2019       26474    1002-1-62   \n",
       "3       12433  Nasjonal Innsjøundersøkelse 2019       26475    1003-1-16   \n",
       "4       12433  Nasjonal Innsjøundersøkelse 2019       26476    1003-1-18   \n",
       "\n",
       "  station_name          sample_date excel_date  depth1  depth2   Al  ...  \\\n",
       "0   Skeivatnet  30.10.2019 00.00.00 2019-10-30       0       0  300  ...   \n",
       "1     Vassvann  29.10.2019 00.00.00 2019-10-29       0       0  130  ...   \n",
       "2      Vråvatn  30.10.2019 00.00.00 2019-10-30       0       0  220  ...   \n",
       "3      HOH 130  30.10.2019 00.00.00 2019-10-30       0       0  160  ...   \n",
       "4       HOH 14  30.10.2019 00.00.00 2019-10-30       0       0  110  ...   \n",
       "\n",
       "  PO4-P  SiO2   SO4 Temperatur  TOC  TOTN TOTP   V   Zn Zn.1  \n",
       "0   < 1  2.51  1.32        8.2  9.2   390    5 NaN  8.3  NaN  \n",
       "1   < 1   2.8  4.13        8.5  6.8   380    6 NaN  8.4  NaN  \n",
       "2    10  2.24  2.19        7.6  7.6   520   15 NaN  5.4  NaN  \n",
       "3   < 1  1.87  1.69        8.1  3.6   280    3 NaN  3.2  NaN  \n",
       "4   < 1   1.1  2.45        8.6  3.3   270    3 NaN  4.4  NaN  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read AM data\n",
    "am_xls = r\"../../../1000_Lakes_AM_Export_2020-06-11_Project_Only.xlsx\"\n",
    "am_df = pd.read_excel(am_xls, sheet_name='WaterChemistry')\n",
    "print(len(am_df))\n",
    "am_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003 stations in the project\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>am_id</th>\n",
       "      <th>station_code</th>\n",
       "      <th>station_name</th>\n",
       "      <th>station_type</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>resa_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26070</td>\n",
       "      <td>221-1-2</td>\n",
       "      <td>Langtjern</td>\n",
       "      <td>Innsjø</td>\n",
       "      <td>11.850274</td>\n",
       "      <td>59.808643</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26071</td>\n",
       "      <td>101-2-7</td>\n",
       "      <td>Hokksjøen</td>\n",
       "      <td>Innsjø</td>\n",
       "      <td>11.563586</td>\n",
       "      <td>59.004423</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26072</td>\n",
       "      <td>402-2-13</td>\n",
       "      <td>Sætertjern</td>\n",
       "      <td>Innsjø</td>\n",
       "      <td>12.446711</td>\n",
       "      <td>60.060222</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26073</td>\n",
       "      <td>419-1-25</td>\n",
       "      <td>Mjøgsjøen</td>\n",
       "      <td>Innsjø</td>\n",
       "      <td>11.842186</td>\n",
       "      <td>60.328578</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26074</td>\n",
       "      <td>425-2-2</td>\n",
       "      <td>Kottern</td>\n",
       "      <td>Innsjø</td>\n",
       "      <td>12.517008</td>\n",
       "      <td>60.590729</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   am_id station_code station_name station_type  longitude   latitude  resa_id\n",
       "0  26070      221-1-2    Langtjern       Innsjø  11.850274  59.808643       10\n",
       "1  26071      101-2-7    Hokksjøen       Innsjø  11.563586  59.004423        9\n",
       "2  26072     402-2-13   Sætertjern       Innsjø  12.446711  60.060222       11\n",
       "3  26073     419-1-25    Mjøgsjøen       Innsjø  11.842186  60.328578       12\n",
       "4  26074      425-2-2      Kottern       Innsjø  12.517008  60.590729       13"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Match station IDs between RESA and AM\n",
    "am_stns = nivapy.da.select_ndb_project_stations([12433], eng, drop_dups=True)\n",
    "am_stns.rename({\"station_id\": \"am_id\"}, inplace=True, axis=1)\n",
    "\n",
    "# Get RESA IDs for AM stations\n",
    "bind_stns = \",\".join(\"(1, %d)\" % i for i in am_stns[\"am_id\"].unique())\n",
    "sql = (\n",
    "    \"SELECT station_id as am_id, \"\n",
    "    \"  local_pk as resa_id \"\n",
    "    \" FROM nivadatabase.datasource_station \"\n",
    "    \"WHERE datasource_id = 11 \"\n",
    "    \"AND (1, station_id) in (%s)\" % bind_stns\n",
    ")\n",
    "stn_link = pd.read_sql(sql, eng)\n",
    "\n",
    "# Join\n",
    "stn_df = pd.merge(am_stns, stn_link, how=\"left\", on=\"am_id\")\n",
    "\n",
    "print(len(stn_df), \"stations in the project\")\n",
    "\n",
    "stn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>water_sample_id</th>\n",
       "      <th>sample_selection_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>871397</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>874269</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>871430</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>871394</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>871393</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   water_sample_id  sample_selection_id\n",
       "0           871397                   67\n",
       "1           874269                   67\n",
       "2           871430                   67\n",
       "3           871394                   67\n",
       "4           871393                   67"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check water samples match in RESA\n",
    "ws_list = []\n",
    "for idx, row in am_df.iterrows():\n",
    "    am_id = row['station_id']\n",
    "    am_date = row['excel_date'].strftime(\"%Y-%m-%d\")\n",
    "    am_dep1 = row['depth1']\n",
    "    am_dep2 = row['depth2']\n",
    "    \n",
    "    resa_id = stn_df.query(\"am_id == @am_id\")['resa_id'].iloc[0]\n",
    "    \n",
    "    sql = (f\"SELECT * FROM resa2.water_samples \"\n",
    "           f\"WHERE station_id = {resa_id} \"\n",
    "           f\"AND sample_date = DATE '{am_date}' \"\n",
    "           f\"AND depth1 = {am_dep1} \"\n",
    "           f\"AND depth2 = {am_dep2}\"\n",
    "          )\n",
    "    ws_df = pd.read_sql(sql, eng)\n",
    "    \n",
    "    assert len(ws_df) == 1, (resa_id, ws_df)\n",
    "\n",
    "    # Get RESA ws id\n",
    "    ws_list.append(ws_df['water_sample_id'].iloc[0])\n",
    "    \n",
    "# Add to sample selections\n",
    "ss_df = pd.DataFrame({'water_sample_id': ws_list})\n",
    "ss_df['sample_selection_id'] = 67\n",
    "print(len(ss_df))\n",
    "\n",
    "ss_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ss_df.to_sql('sample_selections',\n",
    "#             schema='resa2',\n",
    "#             if_exists='append',\n",
    "#             index=False,\n",
    "#             con=eng,\n",
    "#            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Update RESA chemistry to match AM\n",
    "\n",
    "Based on previous checking, TOTN and pH need updating in RESA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RESA par IDs\n",
    "#ph_par_id = 1\n",
    "#totn_par_id = 4\n",
    "#\n",
    "## Get RESA methods for pH\n",
    "#sql = (f\"SELECT wc_method_id FROM resa2.wc_parameters_methods \"\n",
    "#       f\"WHERE wc_parameter_id = {ph_par_id}\"\n",
    "#      )\n",
    "#ph_methods = pd.read_sql(sql, eng)['wc_method_id'].astype(str)\n",
    "#ph_methods = ','.join(ph_methods)\n",
    "#\n",
    "## Get RESA methods for TOTN\n",
    "#sql = (f\"SELECT wc_method_id FROM resa2.wc_parameters_methods \"\n",
    "#       f\"WHERE wc_parameter_id = {totn_par_id}\"\n",
    "#      )\n",
    "#totn_methods = pd.read_sql(sql, eng)['wc_method_id'].astype(str)\n",
    "#totn_methods = ','.join(totn_methods)\n",
    "#\n",
    "## Loop over data\n",
    "#ph_list = []\n",
    "#totn_list = []\n",
    "#for idx, row in am_df.iterrows():\n",
    "#    # Get RESA WS ID\n",
    "#    am_id = row['station_id']\n",
    "#    am_date = row['excel_date'].strftime(\"%Y-%m-%d\")\n",
    "#    am_dep1 = row['depth1']\n",
    "#    am_dep2 = row['depth2']\n",
    "#    \n",
    "#    resa_id = stn_df.query(\"am_id == @am_id\")['resa_id'].iloc[0]\n",
    "#    \n",
    "#    sql = (f\"SELECT * FROM resa2.water_samples \"\n",
    "#           f\"WHERE station_id = {resa_id} \"\n",
    "#           f\"AND sample_date = DATE '{am_date}' \"\n",
    "#           f\"AND depth1 = {am_dep1} \"\n",
    "#           f\"AND depth2 = {am_dep2}\"\n",
    "#          )\n",
    "#    ws_df = pd.read_sql(sql, eng)\n",
    "#    \n",
    "#    assert len(ws_df) == 1, (resa_id, ws_df)\n",
    "#    \n",
    "#    ws_id = ws_df['water_sample_id'].iloc[0]\n",
    "#    \n",
    "#    # Get pH\n",
    "#    sql = (f\"SELECT * FROM resa2.water_chemistry_values2 \"\n",
    "#           f\"WHERE sample_id = {ws_id} \"\n",
    "#           f\"AND method_id IN ({ph_methods})\"\n",
    "#          )\n",
    "#    ph_df = pd.read_sql(sql, eng)\n",
    "#    \n",
    "#    assert len(ph_df) == 1\n",
    "#    \n",
    "#    ph_list.append(ph_df['value'].iloc[0])\n",
    "#    \n",
    "#    # Update RESA pH\n",
    "#    am_ph = row['pH']\n",
    "#    resa_val_id = ph_df['value_id'].iloc[0]\n",
    "#    sql = (f\"UPDATE resa2.water_chemistry_values2 \"\n",
    "#           f\"SET value = {am_ph}, flag1 = NULL \"\n",
    "#           f\"WHERE value_id = {resa_val_id}\"\n",
    "#          )\n",
    "#    eng.execute(sql)    \n",
    "#    \n",
    "#    # Get TOTN\n",
    "#    sql = (f\"SELECT * FROM resa2.water_chemistry_values2 \"\n",
    "#           f\"WHERE sample_id = {ws_id} \"\n",
    "#           f\"AND method_id IN ({totn_methods})\"\n",
    "#          )\n",
    "#    totn_df = pd.read_sql(sql, eng)\n",
    "#    \n",
    "#    # Get the most recent TOTN value\n",
    "#    totn_df = totn_df.loc[[totn_df['entered_date'].idxmax()]]\n",
    "#    \n",
    "#    assert len(totn_df) == 1, totn_df\n",
    "#    \n",
    "#    totn_list.append(totn_df['value'].iloc[0])\n",
    "#    \n",
    "#    # Update RESA TOTN\n",
    "#    am_totn = row['TOTN']\n",
    "#    resa_val_id = totn_df['value_id'].iloc[0]\n",
    "#    sql = (f\"UPDATE resa2.water_chemistry_values2 \"\n",
    "#           f\"SET value = {am_totn}, flag1 = NULL \"\n",
    "#           f\"WHERE value_id = {resa_val_id}\"\n",
    "#          )\n",
    "#    eng.execute(sql) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
