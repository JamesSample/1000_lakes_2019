{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import nivapy3 as nivapy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import geopandas as gpd\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "import importlib.util\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import xarray as xr\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from scipy import stats\n",
    "from collections import defaultdict\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import CL functions\n",
    "# spec = importlib.util.spec_from_file_location(\n",
    "#    \"critical_loads\", \"/home/jovyan/projects/critical_loads_2/notebooks/critical_loads.py\"\n",
    "# )\n",
    "# cl = importlib.util.module_from_spec(spec)\n",
    "# spec.loader.exec_module(cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Nivabase\n",
    "eng = nivapy.da.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare 1995 and 2019 survey results\n",
    "\n",
    "This notebook generates a one-page summary plot for each parameter in the 1000 Lake survey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Stations\n",
    "\n",
    "Read stations and assign to regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get stations\n",
    "stn_df = nivapy.da.select_resa_project_stations([4530], eng)\n",
    "\n",
    "# Assign acid region IDs\n",
    "shp_path = r\"../data/norway_regions.shp\"\n",
    "reg_gdf = gpd.read_file(shp_path)\n",
    "stn_df = nivapy.spatial.identify_point_in_polygon(stn_df, reg_gdf, poly_col=\"name\")\n",
    "\n",
    "print(len(stn_df), \"stations in project.\")\n",
    "\n",
    "stn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get parameters measured in 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time period of interest\n",
    "st_dt = \"2019-08-01\"\n",
    "end_dt = \"2019-12-31\"\n",
    "\n",
    "par_df = nivapy.da.select_resa_station_parameters(\n",
    "    stn_df[\"station_id\"].unique(), st_dt, end_dt, eng\n",
    ")\n",
    "\n",
    "par_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get water chemistry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from 1995\n",
    "wc_95, dups_95 = nivapy.da.select_resa_water_chemistry(\n",
    "    stn_df[\"station_id\"].unique(),\n",
    "    par_df,\n",
    "    \"1995-08-01\",\n",
    "    \"1995-12-31\",\n",
    "    eng,\n",
    "    drop_dups=True,\n",
    ")\n",
    "\n",
    "# Data from 2019\n",
    "wc_19, dups_19 = nivapy.da.select_resa_water_chemistry(\n",
    "    stn_df[\"station_id\"].unique(), par_df, st_dt, end_dt, eng, drop_dups=True\n",
    ")\n",
    "\n",
    "# Get the \"1000 Lakes\" samples\n",
    "# Only surface samples\n",
    "wc_95 = wc_95.query(\"(depth1 == 0) and (depth2 == 0)\")\n",
    "wc_19 = wc_19.query(\"(depth1 == 0) and (depth2 == 0)\")\n",
    "del wc_95[\"depth1\"], wc_95[\"depth2\"], wc_19[\"depth1\"], wc_19[\"depth2\"]\n",
    "\n",
    "# F is only measured for 1000 Lakes\n",
    "wc_95.dropna(subset=[\"F_µg/l\"], inplace=True)\n",
    "wc_19.dropna(subset=[\"F_µg/l\"], inplace=True)\n",
    "\n",
    "assert len(wc_19) == 1001\n",
    "\n",
    "# Remove Åsmundvatnet as sample contaminated with sea water\n",
    "wc_19 = wc_19.query(\"station_code != '1630-1-19'\")\n",
    "\n",
    "# Some concentrations in 1995 are <0. Set to NaN\n",
    "for col in wc_95.columns:\n",
    "    if col not in [\"station_id\", \"station_code\", \"station_name\", \"sample_date\"]:\n",
    "        wc_95[col] = np.where(wc_95[col] < 0, np.nan, wc_95[col])\n",
    "\n",
    "# Calculate averages for stations with multiple samples\n",
    "idx_cols = [\"station_id\", \"station_code\", \"station_name\"]\n",
    "wc_95 = wc_95.groupby(idx_cols).mean().reset_index()\n",
    "wc_19 = wc_19.groupby(idx_cols).mean().reset_index()\n",
    "\n",
    "print(len(wc_95), \"samples in 1995.\")\n",
    "print(len(wc_19), \"samples in 2019.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate derived parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. LAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate LAL\n",
    "wc_95[\"LAL_µg/l\"] = wc_95[\"Al/R_µg/l\"] - wc_95[\"Al/Il_µg/l\"]\n",
    "wc_95[\"LAL_µg/l\"] = np.where(wc_95[\"LAL_µg/l\"] < 0, 0, wc_95[\"LAL_µg/l\"])\n",
    "\n",
    "wc_19[\"LAL_µg/l\"] = wc_19[\"Al/R_µg/l\"] - wc_19[\"Al/Il_µg/l\"]\n",
    "wc_19[\"LAL_µg/l\"] = np.where(wc_19[\"LAL_µg/l\"] < 0, 0, wc_19[\"LAL_µg/l\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. ALK-E\n",
    "\n",
    "See e-mail from Øyvind G received 12.06.2020 at 16:33 for the equation:\n",
    "\n",
    "$$ALKE = (ALK * 1000 - 31.6) + 0.646(ALK * 1000 - 31.6)^{0.5}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ALKE\n",
    "wc_95[\"ALKE_µeq/l\"] = (wc_95[\"ALK_mmol/l\"] * 1000 - 31.6) + 0.646 * (\n",
    "    (wc_95[\"ALK_mmol/l\"] * 1000 - 31.6) ** 0.5\n",
    ")\n",
    "wc_95[\"ALKE_µeq/l\"].fillna(0, inplace=True)\n",
    "\n",
    "wc_19[\"ALKE_µeq/l\"] = (wc_19[\"ALK_mmol/l\"] * 1000 - 31.6) + 0.646 * (\n",
    "    (wc_19[\"ALK_mmol/l\"] * 1000 - 31.6) ** 0.5\n",
    ")\n",
    "wc_19[\"ALKE_µeq/l\"].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. ANC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_anc(df):\n",
    "    \"\"\" Calculate ANC based on data in RESA.\n",
    "    \n",
    "            ANC = (ECa+EMg+EK+ENa+ENH4) - (ECl+ESO4+ENO3)\n",
    "            \n",
    "    Args:\n",
    "        df: Dataframe. As returned by nivapy.da.select_resa_water_chemistry()\n",
    "        \n",
    "    Returns:\n",
    "        The dataframe is returned with a new column, 'ANC_µeq/l', added.\n",
    "    \"\"\"\n",
    "    # Tabulate chemical properties\n",
    "    chem_dict = {\n",
    "        \"molar_mass\": [96.06, 35.45, 40.08, 24.31, 14.01, 39.10, 22.99, 14.01],\n",
    "        \"valency\": [2, 1, 2, 2, 1, 1, 1, 1],\n",
    "        \"resa2_ref_ratio\": [0.103, 1.0, 0.037, 0.196, \"N/A\", 0.018, 0.859, \"N/A\"],\n",
    "    }\n",
    "\n",
    "    chem_df = pd.DataFrame(\n",
    "        chem_dict,\n",
    "        index=[\n",
    "            \"SO4_mg/l\",\n",
    "            \"Cl_mg/l\",\n",
    "            \"Ca_mg/l\",\n",
    "            \"Mg_mg/l\",\n",
    "            \"NO3-N_µg/l N\",\n",
    "            \"K_mg/l\",\n",
    "            \"Na_mg/l\",\n",
    "            \"NH4-N_µg/l N\",\n",
    "        ],\n",
    "    )\n",
    "    chem_df = chem_df[[\"molar_mass\", \"valency\", \"resa2_ref_ratio\"]]\n",
    "\n",
    "    # Convert to microequivalents\n",
    "    for par in [\n",
    "        \"SO4_mg/l\",\n",
    "        \"Cl_mg/l\",\n",
    "        \"Ca_mg/l\",\n",
    "        \"Mg_mg/l\",\n",
    "        \"NO3-N_µg/l N\",\n",
    "        \"K_mg/l\",\n",
    "        \"Na_mg/l\",\n",
    "        \"NH4-N_µg/l N\",\n",
    "    ]:\n",
    "        val = chem_df.loc[par, \"valency\"]\n",
    "        mm = chem_df.loc[par, \"molar_mass\"]\n",
    "\n",
    "        if par == \"NO3-N_µg/l N\":\n",
    "            df[\"ENO3_µeq/l\"] = df[par] * val / mm\n",
    "        elif par == \"NH4-N_µg/l N\":\n",
    "            df[\"ENH4_µeq/l\"] = df[par] * val / mm\n",
    "        else:\n",
    "            name = par.split(\"_\")[0]\n",
    "            df[f\"E{name}_µeq/l\"] = df[par] * val * 1000.0 / mm\n",
    "\n",
    "    #    # Apply sea-salt correction\n",
    "    #    for par in ['ESO4_µeq/l', 'EMg_µeq/l', 'ECa_µeq/l']:#, 'ENa_µeq/l', 'EK_µeq/l']:\n",
    "    #        ref = chem_df.loc[par.split('_')[0][1:]+'_mg/l', 'resa2_ref_ratio']\n",
    "    #        df[par] = df[par] - (ref*df['ECl_µeq/l'])\n",
    "\n",
    "    # Calculate ANC = (ECa+EMg+EK+ENa+ENH4) - (ECl+ESO4+ENO3)\n",
    "    df[\"ANC_µeq/l\"] = (\n",
    "        df[\"ECa_µeq/l\"]\n",
    "        + df[\"EMg_µeq/l\"]\n",
    "        + df[\"EK_µeq/l\"]\n",
    "        + df[\"ENa_µeq/l\"]\n",
    "        + df[\"ENH4_µeq/l\"]\n",
    "    ) - (df[\"ECl_µeq/l\"] + df[\"ESO4_µeq/l\"] + df[\"ENO3_µeq/l\"])\n",
    "\n",
    "    # Remove intermediates\n",
    "    df.drop(\n",
    "        [\n",
    "            \"ESO4_µeq/l\",\n",
    "            \"ECl_µeq/l\",\n",
    "            \"EMg_µeq/l\",\n",
    "            \"ECa_µeq/l\",\n",
    "            \"ENO3_µeq/l\",\n",
    "            \"EK_µeq/l\",\n",
    "            \"ENa_µeq/l\",\n",
    "            \"ENH4_µeq/l\",\n",
    "        ],\n",
    "        axis=1,\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ANC\n",
    "wc_95 = calculate_anc(wc_95)\n",
    "wc_19 = calculate_anc(wc_19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_points(\n",
    "    df,\n",
    "    par,\n",
    "    ax,\n",
    "    lat=\"latitude\",\n",
    "    lon=\"longitude\",\n",
    "    cmap=\"coolwarm\",\n",
    "    s=10,\n",
    "    title=None,\n",
    "    vmin=None,\n",
    "    vmax=None,\n",
    "    vmax_pct=0.975,\n",
    "    vmin_pct=0.025,\n",
    "    cbar_ticks=None,\n",
    "    cbar_labels=None,\n",
    "):\n",
    "    \"\"\" Plot Norwegian point data on specified axis.\n",
    "    \"\"\"\n",
    "\n",
    "    if vmax and vmax_pct:\n",
    "        raise ValueError(\"Please specify 'vmax' or 'vmax_pct', not both.\")\n",
    "\n",
    "    # Plot Norway\n",
    "    shp = cartopy.io.shapereader.natural_earth(\n",
    "        resolution=\"50m\", category=\"cultural\", name=\"admin_0_countries\"\n",
    "    )\n",
    "    reader = cartopy.io.shapereader.Reader(shp)\n",
    "    countries = reader.records()\n",
    "\n",
    "    # Add Norway outline\n",
    "    for country in countries:\n",
    "        if country.attributes[\"NAME\"] == \"Norway\":\n",
    "            ax.add_geometries(\n",
    "                [country.geometry],\n",
    "                ccrs.PlateCarree(),  # CRS of Natural Earth data\n",
    "                facecolor=\"none\",\n",
    "                edgecolor=\"black\",\n",
    "                linewidth=1,\n",
    "                zorder=5,\n",
    "            )\n",
    "\n",
    "    if vmax_pct:\n",
    "        vmax = df[par].describe(percentiles=[0.975,]).loc[\"97.5%\"]\n",
    "\n",
    "    if vmin_pct:\n",
    "        vmin = df[par].describe(percentiles=[0.025,]).loc[\"2.5%\"]\n",
    "\n",
    "    # Add points using linear colour ramp from 0 to vmax\n",
    "    pts = ax.scatter(\n",
    "        df[lon].values,\n",
    "        df[lat].values,\n",
    "        c=df[par].values,\n",
    "        cmap=cmap,\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "        s=s,\n",
    "        zorder=5,\n",
    "        edgecolors=\"none\",\n",
    "        transform=ccrs.PlateCarree(),\n",
    "    )\n",
    "\n",
    "    # Add axis for colourbar\n",
    "    cax = inset_axes(\n",
    "        ax,\n",
    "        width=\"5%\",\n",
    "        height=\"30%\",\n",
    "        loc=\"lower left\",\n",
    "        bbox_to_anchor=(0.8, 0.05, 1, 1),\n",
    "        bbox_transform=ax.transAxes,\n",
    "        borderpad=0,\n",
    "    )\n",
    "\n",
    "    # Add colourbar\n",
    "    cbar = fig.colorbar(pts, cax=cax, ticks=cbar_ticks)\n",
    "    if cbar_labels:\n",
    "        cbar.ax.set_yticklabels(cbar_labels)\n",
    "\n",
    "    # Turn off border around subplot\n",
    "    ax.outline_patch.set_edgecolor(\"white\")\n",
    "\n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=12, loc=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data below is taken from Øyvind's spreadsheet (see e-mail received 15.06.2020 at 11:19."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set scale choices for scatterplots from Øyvind's spreadsheet\n",
    "# (log_xy, lod_1995, lod_2019)\n",
    "axis_opt_df = pd.read_excel(r\"../data/axis_options_oga.xlsx\")\n",
    "axis_opt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del axis_opt_df[\"unit\"]\n",
    "axis_opt_df.set_index(\"parameter\", inplace=True)\n",
    "axis_opt_dict = axis_opt_df.T.apply(tuple).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Compare 2019 and 1995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_dict = {\n",
    "    \"par\": [],\n",
    "    \"region\": [],\n",
    "    \"p_val\": [],\n",
    "    \"signif\": [],\n",
    "}\n",
    "\n",
    "par_label_dict = defaultdict(lambda: None)\n",
    "par_label_dict['SO4'] = '$SO_4$'\n",
    "\n",
    "# Loop over parameters\n",
    "for col in wc_19.columns:\n",
    "    if col in wc_95.columns:\n",
    "        if col not in idx_cols:\n",
    "            par, unit = col.split(\"_\")\n",
    "            \n",
    "            if par_label_dict[par] is not None:\n",
    "                par_label = par_label_dict[par]\n",
    "            else:\n",
    "                par_label = par\n",
    "                \n",
    "            print(\"Processing:\", par)\n",
    "\n",
    "            # Get 2019 data\n",
    "            df19 = wc_19[[\"station_id\", col]].dropna()\n",
    "            nvals = len(df19)\n",
    "\n",
    "            # Join co-ords\n",
    "            df19 = pd.merge(\n",
    "                df19,\n",
    "                stn_df[[\"station_id\", \"latitude\", \"longitude\", \"name\"]],\n",
    "                how=\"left\",\n",
    "                on=\"station_id\",\n",
    "            )\n",
    "\n",
    "            df9519 = pd.merge(\n",
    "                df19,\n",
    "                wc_95[[\"station_id\", col]],\n",
    "                how=\"left\",\n",
    "                on=\"station_id\",\n",
    "                suffixes=[\"_19\", \"_95\"],\n",
    "            ).dropna()\n",
    "\n",
    "            # Calc ratio 2019:1995\n",
    "            df9519[\"ratio_2019:1995\"] = df9519[col + \"_19\"] / df9519[col + \"_95\"]\n",
    "            df9519[\"log(ratio_2019:1995)\"] = np.log10(df9519[\"ratio_2019:1995\"])\n",
    "\n",
    "            # Melt to lon\n",
    "            melt_df = df9519[[\"station_id\", \"name\", col + \"_95\", col + \"_19\"]].copy()\n",
    "            melt_df.columns = [\"station_id\", \"Region\", \"1995\", \"2019\"]\n",
    "            melt_df = pd.melt(\n",
    "                melt_df,\n",
    "                id_vars=[\"station_id\", \"Region\"],\n",
    "                var_name=\"Year\",\n",
    "                value_name=f\"{par_label} ({unit})\",\n",
    "            )\n",
    "\n",
    "            # Define co-ord system\n",
    "            crs = ccrs.AlbersEqualArea(\n",
    "                central_longitude=15,\n",
    "                central_latitude=65,\n",
    "                false_easting=650000,\n",
    "                false_northing=800000,\n",
    "                standard_parallels=(55, 75),\n",
    "            )\n",
    "\n",
    "            # Setup plot template\n",
    "            fig = plt.figure(figsize=(12, 15))\n",
    "            gs = fig.add_gridspec(ncols=2, nrows=5)\n",
    "            ax1 = fig.add_subplot(gs[0:3, 0], projection=crs)\n",
    "            ax1.set_extent([0, 1300000, 0, 1600000], crs=crs)\n",
    "\n",
    "            ax2 = fig.add_subplot(gs[0:3, 1], projection=crs)\n",
    "            ax2.set_extent([0, 1300000, 0, 1600000], crs=crs)\n",
    "\n",
    "            #            ax3 = fig.add_subplot(gs[2, 0])\n",
    "            #            ax4 = fig.add_subplot(gs[2, 1])\n",
    "            ax3 = fig.add_subplot(gs[3:, :], aspect=\"equal\")\n",
    "\n",
    "            # Plot values in 2019\n",
    "            if par == \"pH\":\n",
    "                title = f\"(a) {par_label} i 2019 (n = {nvals})\"\n",
    "                cmap = 'coolwarm_r'\n",
    "            else:\n",
    "                title = f\"(a) {par_label} i 2019 ({unit}; n = {nvals})\"\n",
    "                cmap = 'coolwarm'\n",
    "\n",
    "            plot_points(df19, par=col, ax=ax1, cmap=cmap, title=title)\n",
    "\n",
    "            # Plot ratio of values 2019:1995\n",
    "            if par == \"pH\":\n",
    "                # Plot pH ratios directly\n",
    "                plot_points(\n",
    "                    df9519,\n",
    "                    par=\"ratio_2019:1995\",\n",
    "                    ax=ax2,\n",
    "                    cmap='coolwarm_r',\n",
    "                    # vmin=-1,\n",
    "                    # vmax=1,\n",
    "                    # vmax_pct=None,\n",
    "                    title=\"(b) Verdi 2019 / Verdi 1995\",\n",
    "                    # cbar_ticks=[-1, -0.7, -0.3, 0, 0.3, 0.7, 1],\n",
    "                    # cbar_labels=[\"÷10\", \"÷5\", \"÷2\", \"Equal\", \"x2\", \"x5\", \"x10\"],\n",
    "                )\n",
    "            else:\n",
    "                # Plor log ratio\n",
    "                plot_points(\n",
    "                    df9519,\n",
    "                    par=\"log(ratio_2019:1995)\",\n",
    "                    ax=ax2,\n",
    "                    vmin=-1,\n",
    "                    vmax=1,\n",
    "                    vmax_pct=None,\n",
    "                    vmin_pct=None,\n",
    "                    title=\"(b) log(Verdi 2019 / Verdi 1995)\",\n",
    "                    cbar_ticks=[-1, -0.7, -0.3, 0, 0.3, 0.7, 1],\n",
    "                    cbar_labels=[\"÷10\", \"÷5\", \"÷2\", \"Lik\", \"x2\", \"x5\", \"x10\"],\n",
    "                )\n",
    "\n",
    "            #            # Plot CDF\n",
    "            #            # If IQR of data is zero (e.g. because most values are LOD), Seaborn fails to\n",
    "            #            # select bandwidth for KDE. See https://github.com/mwaskom/seaborn/issues/1990\n",
    "            #            # Set bandwidth for F in 1995 manually\n",
    "            #            if par == \"F\":\n",
    "            #                sn.distplot(\n",
    "            #                    df9519[col + \"_95\"],\n",
    "            #                    hist=False,\n",
    "            #                    kde_kws={\"cumulative\": True, \"bw\": 0.1},\n",
    "            #                    ax=ax3,\n",
    "            #                    label=\"1995\",\n",
    "            #                )\n",
    "            #\n",
    "            #            else:\n",
    "            #                sn.distplot(\n",
    "            #                    df9519[col + \"_95\"],\n",
    "            #                    hist=False,\n",
    "            #                    kde_kws={\"cumulative\": True},\n",
    "            #                    ax=ax3,\n",
    "            #                    label=\"1995\",\n",
    "            #                )\n",
    "            #\n",
    "            #            sn.distplot(\n",
    "            #                df9519[col + \"_19\"].values,\n",
    "            #                hist=False,\n",
    "            #                kde_kws={\"cumulative\": True},\n",
    "            #                ax=ax3,\n",
    "            #                label=\"2019\",\n",
    "            #            )\n",
    "            #\n",
    "            #            ax3.set_title(\n",
    "            #                \"(c) Cumulative distribution functions\", fontsize=12, loc=\"left\"\n",
    "            #            )\n",
    "            #            ax3.set_xlabel(f\"{par} ({unit})\", fontsize=10)\n",
    "            #            ax3.set_ylabel(\"Probability\", fontsize=10)\n",
    "\n",
    "            #            # Scatter plot\n",
    "            #            ax3.plot(\n",
    "            #                df9519[col + \"_95\"],\n",
    "            #                df9519[col + \"_19\"],\n",
    "            #                c=df9519[\"name\"],\n",
    "            #                fillstyle=\"none\",\n",
    "            #                markeredgewidth=0.5,\n",
    "            #            )\n",
    "\n",
    "            # Scatter plot\n",
    "            df9519.rename({\"name\": \"Region\"}, axis=1, inplace=True)\n",
    "            sn.scatterplot(\n",
    "                x=df9519[col + \"_95\"],\n",
    "                y=df9519[col + \"_19\"],\n",
    "                hue=df9519[\"Region\"],\n",
    "                ax=ax3,\n",
    "            )\n",
    "\n",
    "            ax3.plot(\n",
    "                df9519[col + \"_19\"],\n",
    "                df9519[col + \"_19\"],\n",
    "                ls=\"--\",\n",
    "                c=\"0.5\",\n",
    "                label=\"1:1 line\",\n",
    "            )\n",
    "\n",
    "            log, lod95, lod19 = axis_opt_dict[par]\n",
    "\n",
    "            if ~np.isnan(lod95):\n",
    "                # Add LOD for 1995\n",
    "                ax3.axvline(lod95, color=\"0.5\", ls=\":\")\n",
    "\n",
    "            if ~np.isnan(lod19):\n",
    "                # Add LOD for 1995\n",
    "                ax3.axhline(lod19, color=\"0.5\", ls=\":\", label=\"LOD\")\n",
    "\n",
    "            if log:\n",
    "                ax3.set(xscale=\"log\", yscale=\"log\")\n",
    "\n",
    "            ax3.legend(loc=\"best\")\n",
    "            ax3.set_title(\"(c) Scatterplott\", fontsize=12, loc=\"left\")\n",
    "            if par == 'pH':\n",
    "                ax3.set_xlabel(f\"{par_label} i 1995\", fontsize=10)\n",
    "                ax3.set_ylabel(f\"{par_label} i 2019\", fontsize=10)\n",
    "            else:\n",
    "                ax3.set_xlabel(f\"{par_label} i 1995 ({unit})\", fontsize=10)\n",
    "                ax3.set_ylabel(f\"{par_label} i 2019 ({unit})\", fontsize=10)\n",
    "\n",
    "            #            # Ensure plot is square\n",
    "            #            ax_min = min(ax3.get_xlim()[0], ax3.get_ylim()[0])\n",
    "            #            ax_max = max(ax3.get_xlim()[1], ax3.get_ylim()[1])\n",
    "            #            ax3.set_xlim((ax_min, ax_max))\n",
    "            #            ax3.set_ylim((ax_min, ax_max))\n",
    "\n",
    "            #            # Box plots\n",
    "            #            box = sn.violinplot(\n",
    "            #                data=melt_df, x=\"Region\", y=f\"{par} ({unit})\", hue=\"Year\", ax=ax5\n",
    "            #            )\n",
    "            #            box.set_xticklabels(box.get_xticklabels(), rotation=30, ha=\"right\")\n",
    "            #            ax5.set_title(\"(e) Violin plots\", fontsize=12, loc=\"left\")\n",
    "\n",
    "            plt.suptitle(par_label, fontsize=20, y=0.9, fontweight=\"bold\")\n",
    "            plt.subplots_adjust(hspace=0)\n",
    "\n",
    "            # Save\n",
    "            png_path = f\"../output/summary_plots_1995-2019/1000_lakes_1995-2019_{par.replace('/', '-').lower()}.png\"\n",
    "            plt.savefig(png_path, dpi=200)\n",
    "            plt.close()\n",
    "\n",
    "            # Paired sample t-test\n",
    "            for region in df9519[\"Region\"].unique():\n",
    "                ttest_df = df9519.query(\"Region == @region\")\n",
    "                tstat, pval = stats.ttest_rel(\n",
    "                    ttest_df[col + \"_95\"], ttest_df[col + \"_19\"]\n",
    "                )\n",
    "                if pval < 0.05:\n",
    "                    signif = \"yes\"\n",
    "                else:\n",
    "                    signif = \"no\"\n",
    "\n",
    "                ttest_dict[\"par\"].append(par)\n",
    "                ttest_dict[\"region\"].append(region)\n",
    "                ttest_dict[\"p_val\"].append(pval)\n",
    "                ttest_dict[\"signif\"].append(signif)\n",
    "\n",
    "ttest_df = pd.DataFrame(ttest_dict)\n",
    "\n",
    "ttest_csv = r\"../output/parired_ttest_by_region.csv\"\n",
    "ttest_df.to_csv(ttest_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Plot all parameters from 2019\n",
    "\n",
    "**Added 18.06.2020:** Need a different layout to allow for parameters not measured in 1995 (where the above approach would create \"empty-looking\" plots). We also need to incorporate data based on UVAbs measurements from Cathrine (see e-mails from Atle and Øyvind received 18.06.2020 for details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read UVAbs data from Cathrine\n",
    "uv_path = r\"../data/1000Lakes_Abs.txt\"\n",
    "uvdf = pd.read_csv(uv_path, sep=\"\\t\")\n",
    "uvdf.rename({\"Stasjonskode\": \"station_code\"}, axis=1, inplace=True)\n",
    "uvdf.drop(\n",
    "    [\"Prøvenr\", \"Station.ID\", \"Stasjonsnavn\", \"Station.name\", \"Date\", \"DOC\", \"TOC\"],\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    ")\n",
    "uvdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join to other chem from 2019\n",
    "wc_19 = pd.merge(wc_19, uvdf, how=\"left\", on=\"station_code\")\n",
    "wc_19.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_19[pd.isna(wc_19[\"Abs280_[-]\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over parameters\n",
    "for col in wc_19.columns:\n",
    "    if col not in idx_cols:\n",
    "        par, unit = col.split(\"_\")\n",
    "        print(\"Processing:\", par)\n",
    "\n",
    "        # Get 2019 data\n",
    "        df19 = wc_19[[\"station_id\", col]].dropna()\n",
    "        nvals = len(df19)\n",
    "\n",
    "        if nvals > 900:\n",
    "            # Join co-ords\n",
    "            df19 = pd.merge(\n",
    "                df19,\n",
    "                stn_df[[\"station_id\", \"latitude\", \"longitude\", \"name\"]],\n",
    "                how=\"left\",\n",
    "                on=\"station_id\",\n",
    "            )\n",
    "\n",
    "            # Define co-ord system\n",
    "            crs = ccrs.AlbersEqualArea(\n",
    "                central_longitude=15,\n",
    "                central_latitude=65,\n",
    "                false_easting=650000,\n",
    "                false_northing=800000,\n",
    "                standard_parallels=(55, 75),\n",
    "            )\n",
    "\n",
    "            # Setup plot template\n",
    "            fig = plt.figure(figsize=(8, 12))\n",
    "            gs = fig.add_gridspec(ncols=1, nrows=3)\n",
    "\n",
    "            ax1 = fig.add_subplot(gs[0:2, 0], projection=crs)\n",
    "            ax1.set_extent([0, 1300000, 0, 1600000], crs=crs)\n",
    "\n",
    "            ax2 = fig.add_subplot(gs[2, 0])\n",
    "\n",
    "            # Plot values in 2019\n",
    "            if (unit == \"\") or (unit == \"[-]\"):\n",
    "                title = f\"(a) {par} i 2019 (n = {nvals})\"\n",
    "            else:\n",
    "                title = f\"(a) {par} i 2019 ({unit}; n = {nvals})\"\n",
    "\n",
    "            plot_points(df19, par=col, ax=ax1, title=title)\n",
    "\n",
    "            # Box plots\n",
    "            log, lod95, lod19 = axis_opt_dict[par]\n",
    "\n",
    "            if ~np.isnan(lod19):\n",
    "                # Add LOD for 2019\n",
    "                ax2.axhline(lod19, color=\"0.5\", ls=\":\", label=\"LOD\")\n",
    "\n",
    "            if log:\n",
    "                ax2.set(yscale=\"log\")\n",
    "\n",
    "            if (unit == \"\") or (unit == \"[-]\"):\n",
    "                col_name = f\"{par} ([-])\"\n",
    "                df19.rename(\n",
    "                    {\"name\": \"Region\", col: col_name}, axis=1, inplace=True\n",
    "                )\n",
    "            else:\n",
    "                col_name = f\"{par} ({unit})\"\n",
    "                df19.rename(\n",
    "                    {\"name\": \"Region\", col: col_name}, axis=1, inplace=True\n",
    "                )\n",
    "            box = sn.boxplot(data=df19, x=\"Region\", y=col_name, ax=ax2)\n",
    "            box.set_xticklabels(box.get_xticklabels(), rotation=30, ha=\"right\")\n",
    "            ax2.set_title(\"(b) Boksplotter\", fontsize=12, loc=\"left\")\n",
    "            ax2.legend()\n",
    "\n",
    "            plt.suptitle(par, fontsize=20, y=0.95, fontweight=\"bold\")\n",
    "            plt.subplots_adjust(hspace=0.2)\n",
    "\n",
    "            # Save\n",
    "            png_path = f\"../output/summary_plots_2019_only/1000_lakes_2019_{par.replace('/', '-').lower()}.png\"\n",
    "            plt.savefig(png_path, dpi=200)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Runoff and deposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Runoff\n",
    "\n",
    "Maps of runoff based on ERA5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read nc\n",
    "nc_path = r\"../../../era5_tmp_pptn_runoff_1979-2019_monthly.nc\"\n",
    "ds = xr.open_dataset(nc_path)\n",
    "\n",
    "# 'expver' = 1 is up to end of 2019; 'expver' = 2 is for most recent data\n",
    "ds = ds.sel(expver=1).drop(\"expver\")\n",
    "\n",
    "ds = ds.load()\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert average runoff and pptn over month in m/day to mm/month\n",
    "ds[\"ro\"] = ds[\"ro\"] * ds[\"ro\"].time.dt.days_in_month * 1000\n",
    "ds[\"tp\"] = ds[\"tp\"] * ds[\"tp\"].time.dt.days_in_month * 1000\n",
    "\n",
    "# Convert K to C\n",
    "ds[\"t2m\"] = ds[\"t2m\"] - 273.15\n",
    "\n",
    "\n",
    "# Aggregate to annual\n",
    "ro = ds[\"ro\"].resample({\"time\": \"A\"}).sum()\n",
    "tp = ds[\"tp\"].resample({\"time\": \"A\"}).sum()\n",
    "tmp = ds[\"t2m\"].resample({\"time\": \"A\"}).mean()\n",
    "\n",
    "# Use ro == 0 as no data mask\n",
    "tmp = tmp.where(ro != 0)\n",
    "tp = tp.where(ro != 0)\n",
    "ro = ro.where(ro != 0)\n",
    "\n",
    "ds2 = xr.merge([ro, tp, tmp])\n",
    "ds2[\"time\"] = ds2[\"time\"].dt.year\n",
    "\n",
    "ds2 = ds2.rename(\n",
    "    {\"ro\": \"Avrenning (mm)\", \"tp\": \"Nedbør (mm)\", \"t2m\": \"Temperatur (°C)\"}\n",
    ")\n",
    "\n",
    "ds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define co-ord system\n",
    "crs = ccrs.AlbersEqualArea(\n",
    "    central_longitude=15,\n",
    "    central_latitude=65,\n",
    "    false_easting=650000,\n",
    "    false_northing=800000,\n",
    "    standard_parallels=(55, 75),\n",
    ")\n",
    "\n",
    "# Setup plot\n",
    "fig = plt.figure(figsize=(12, 18))\n",
    "axes = []\n",
    "for i in range(6):\n",
    "    ax = fig.add_subplot(3, 2, i + 1, projection=crs)\n",
    "    ax.set_extent([0, 1300000, 0, 1600000], crs=crs)\n",
    "    axes.append(ax)\n",
    "\n",
    "# Plot vars\n",
    "ds2[\"Nedbør (mm)\"].sel(time=1995).plot.contourf(\n",
    "    ax=axes[0], vmin=300, vmax=3500, transform=ccrs.PlateCarree()\n",
    ")\n",
    "ds2[\"Nedbør (mm)\"].sel(time=2019).plot.contourf(\n",
    "    ax=axes[1], vmin=300, vmax=3500, transform=ccrs.PlateCarree()\n",
    ")\n",
    "ds2[\"Temperatur (°C)\"].sel(time=1995).plot.contourf(\n",
    "    ax=axes[2], vmax=15, transform=ccrs.PlateCarree()\n",
    ")\n",
    "ds2[\"Temperatur (°C)\"].sel(time=2019).plot.contourf(\n",
    "    ax=axes[3], vmax=15, transform=ccrs.PlateCarree()\n",
    ")\n",
    "ds2[\"Avrenning (mm)\"].sel(time=1995).plot.contourf(\n",
    "    ax=axes[4], vmin=0, vmax=2000, transform=ccrs.PlateCarree()\n",
    ")\n",
    "ds2[\"Avrenning (mm)\"].sel(time=2019).plot.contourf(\n",
    "    ax=axes[5], vmin=0, vmax=2000, transform=ccrs.PlateCarree()\n",
    ")\n",
    "\n",
    "# Define Natural Earth data\n",
    "# Land\n",
    "land_50m = cfeature.NaturalEarthFeature(\n",
    "    category=\"cultural\",\n",
    "    name=\"admin_0_countries\",\n",
    "    scale=\"50m\",\n",
    "    edgecolor=\"black\",\n",
    "    facecolor=\"none\",\n",
    "    linewidth=1,\n",
    ")\n",
    "# Sea\n",
    "sea_50m = cfeature.NaturalEarthFeature(\n",
    "    category=\"physical\", name=\"ocean\", scale=\"50m\", edgecolor=\"none\", facecolor=\"white\",\n",
    ")\n",
    "\n",
    "# Add geo data\n",
    "[ax.add_feature(sea_50m) for ax in axes]\n",
    "[ax.add_feature(land_50m) for ax in axes]\n",
    "\n",
    "axes[0].set_title(\"Årlig nedbør i 1995\")\n",
    "axes[1].set_title(\"Årlig nedbør i 2019\")\n",
    "axes[2].set_title(\"Årlig temperatur i 1995\")\n",
    "axes[3].set_title(\"Årlig temperatur i 2019\")\n",
    "axes[4].set_title(\"Årlig avrenning i 1995\")\n",
    "axes[5].set_title(\"Årlig avrenning i 2019\")\n",
    "\n",
    "png_path = r\"../output/pptn_temp_runoff_1995-2019.png\"\n",
    "plt.savefig(png_path, dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Deposition\n",
    "\n",
    "The following code needs to be run on the JupyterHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to PostGIS\n",
    "eng = nivapy.da.connect_postgis(database=\"critical_loads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show series already in database\n",
    "with pd.option_context(\"display.max_colwidth\", -1):\n",
    "    ser_grid = cl.view_dep_series(eng)\n",
    "\n",
    "    # Just data of interest\n",
    "    ser_grid = ser_grid.query(\"grid == 'blr'\")\n",
    "\n",
    "    display(ser_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get deposition data\n",
    "short_names = [\"9296\", \"1216_old\"]\n",
    "\n",
    "title_dict = {\n",
    "    \"9296\": \"1992 - 1996\",\n",
    "    \"1216_old\": \"2012 - 2016\",\n",
    "}\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 16))\n",
    "\n",
    "for idx, name in enumerate(short_names):\n",
    "    series_id = int(ser_grid.query(\"short_name == @name\")[\"series_id\"].values[0])\n",
    "\n",
    "    # Get dep data\n",
    "    n_gdf = cl.extract_deposition_as_gdf(series_id, \"nitrogen\", eng)\n",
    "    s_gdf = cl.extract_deposition_as_gdf(series_id, \"sulphur\", eng)\n",
    "\n",
    "    # Plot N\n",
    "    cax_n = inset_axes(\n",
    "        axes[idx, 0],\n",
    "        width=\"5%\",\n",
    "        height=\"30%\",\n",
    "        loc=\"lower left\",\n",
    "        bbox_to_anchor=(0.8, 0.05, 1, 1),\n",
    "        bbox_transform=axes[idx, 0].transAxes,\n",
    "        borderpad=0,\n",
    "    )\n",
    "\n",
    "    n_gdf.plot(\n",
    "        column=\"ndep_meqpm2pyr\",\n",
    "        cmap=\"coolwarm\",\n",
    "        edgecolor=None,\n",
    "        legend=True,\n",
    "        vmin=0,\n",
    "        vmax=100,\n",
    "        ax=axes[idx, 0],\n",
    "        cax=cax_n,\n",
    "    )\n",
    "\n",
    "    axes[idx, 0].set_title(\n",
    "        \"Gjennomsnittlig N avsetning %s\\n($meq.m^{-2}.yr^{-1})$\" % title_dict[name]\n",
    "    )\n",
    "\n",
    "    # Plot S\n",
    "    cax_s = inset_axes(\n",
    "        axes[idx, 1],\n",
    "        width=\"5%\",\n",
    "        height=\"30%\",\n",
    "        loc=\"lower left\",\n",
    "        bbox_to_anchor=(0.8, 0.05, 1, 1),\n",
    "        bbox_transform=axes[idx, 1].transAxes,\n",
    "        borderpad=0,\n",
    "    )\n",
    "\n",
    "    s_gdf.plot(\n",
    "        column=\"sdep_meqpm2pyr\",\n",
    "        cmap=\"coolwarm\",\n",
    "        edgecolor=None,\n",
    "        ax=axes[idx, 1],\n",
    "        legend=True,\n",
    "        vmin=0,\n",
    "        vmax=100,\n",
    "        cax=cax_s,\n",
    "    )\n",
    "\n",
    "    axes[idx, 1].set_title(\n",
    "        \"Gjennomsnittlig S avsetning %s\\n($meq.m^{-2}.yr^{-1})$\" % title_dict[name]\n",
    "    )\n",
    "\n",
    "[ax.set_axis_off() for ax in axes.flatten()]\n",
    "\n",
    "png_path = r\"../output/n_s_deposition_1996-2016.png\"\n",
    "plt.savefig(png_path, dpi=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
